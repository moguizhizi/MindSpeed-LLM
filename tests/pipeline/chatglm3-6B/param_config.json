 {
    "test_chatglm3_6B_mmlu_evaluate": [
        {
            "param": {
                "task-data-path":"/data/eval_data/mmlu/data/test/",
                "task":"mmlu",
                "seq-length": 8192,
                "max-new-tokens": 1,
                "max-position-embeddings": 8192,
                "tensor-model-parallel-size": 2,
                "pipeline-model-parallel-size": 4,
                "num-layers": 28,
                "hidden-size": 4096,
                "ffn-hidden-size": 13696,
                "num-attention-heads": 32,
                "group-query-attention": null,
                "num-query-groups": 2,
                "disable-bias-linear": null,
                "add-qkv-bias": null,
                "swiglu": null,
                "padded-vocab-size": 65024,
                "make-vocab-size-divisible-by": 1,
                "position-embedding-type": "rope",
                "use-partial-rope": null,
                "load":"/data/pipeline/chatglm3-6b-base-mg-tp1pp2-legacy-base",
                "normalization": "RMSNorm",
                "tokenizer-type":"PretrainedFromHF",
                "tokenizer-name-or-path":"/data/hf/chatglm3-6b-base-hf/",
                "tokenizer-not-use-fast": null,
                "fp16": null,
                "micro-batch-size": 1,
                "exit-on-missing-checkpoint": null,
                "no-load-rng": null,
                "no-load-optim": null,
                "untie-embeddings-and-output-weights": null,
                "seed": 42
            }
        }
    ],

    "test_chatglm3_6B_greedy_search": [
        {
            "param": {
                "tensor-model-parallel-size": 1,
                "pipeline-model-parallel-size": 2,
                "num-layers": 28,
                "hidden-size": 4096,
                "ffn-hidden-size": 13696,
                "seq-length": 8192,
                "group-query-attention": null,
                "num-query-groups": 2,
                "num-attention-heads": 32,
                "padded-vocab-size": 65024,
                "make-vocab-size-divisible-by": 1,
                "max-position-embeddings": 8192,
                "position-embedding-type": "rope",
                "use-glm-rope": null,
                "rotary-percent": 0.5,
                "disable-bias-linear": null,
                "add-qkv-bias": null,
                "swiglu": null,
                "normalization": "RMSNorm",
                "max-new-tokens": 8,
                "micro-batch-size": 1,
                "global-batch-size": 16,
                "load":"/data/pipeline/chatglm3-6b-base-mg-tp1pp2-legacy-base",
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path":"/data/hf/chatglm3-6b-base-hf/",
                "tokenizer-model": "/data/hf/chatglm3-6b-base-hf/tokenizer.model",
                "tokenizer-not-use-fast": null,
                "untie-embeddings-and-output-weights": null,
                "attention-softmax-in-fp32": null,
                "no-load-optim": null,
                "no-load-rng": null,
                "no-masked-softmax-fusion": null,
                "no-gradient-accumulation-fusion": null,
                "exit-on-missing-checkpoint": null,
                "seed": 42,
                "fp16": null,
                "task": "greedy",
                "use-deter-comp": null
            }
        }
    ],

    "test_preprocess_pretrain_data": [
        {
            "param": {
                "input": "/data/train-00000-of-00001-a09b74b3ef9c3b56.parquet",
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path": "/data/hf/chatglm3-6b-base-hf/"
            },
            "prefix": "alpaca"
        }
    ],

    "test_chatglm3_hf2legacy_tp2pp4": [
        {
            "param": {
                "model-type": "GPT",
                "load-model-type": "hf",
                "save-model-type": "mg",
                "model-type-hf": "chatglm3",
                "add-qkv-bias": null,
                "target-tensor-parallel-size": "2",
                "target-pipeline-parallel-size": "4",
                "load-dir": "/data/hf/chatglm3-6b-base-hf/",
                "save-dir": "/data/cache/",
                "tokenizer-model": "/data/hf/chatglm3-6b-base-hf/tokenizer.model"
            }
        },
        {
            "Base_MD5" : [
                "be7a2d86d98c3a27",
                "ea92035af1b70568",
                "4e9b7c76f4dea6df",
                "4499e7c0b47ac75f",
                "03066db39b46ec95",
                "081a7370d18ccf82",
                "ce717135cb55a0b9",
                "143041bf67d98e24"
            ]
        }
    ]
}