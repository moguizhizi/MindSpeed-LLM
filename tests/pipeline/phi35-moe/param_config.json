 {
    "test_phi35_moe_mmlu_evaluate": [
        {
            "param": {
                "use-mcore-models": null,
                "no-chat-template": null,
                "moe-grouped-gemm": null,
                "spec": ["mindspeed_llm.tasks.models.spec.phi35_moe_spec", "layer_spec"],
                "task": "mmlu",
                "task-data-path": "/data/eval_data/mmlu/data/test",
                "tensor-model-parallel-size": 1,
                "pipeline-model-parallel-size": 8,
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path": "/data/hf/Phi-3.5-MoE-instruct-hf",
                "seq-length": 4096,
                "max-position-embeddings": 131072,
                "num-layers": 32,
                "hidden-size": 4096,
                "ffn-hidden-size": 6400,
                "num-attention-heads": 32,
                "group-query-attention": null,
                "num-query-groups": 8,
                "num-experts": 16,
                "moe-router-topk": 2,
                "moe-router-load-balancing-type": "sparsemixer_topk",
                "moe-input-jitter-eps": 0.01,
                "moe-permutation-async-comm": null,
                "swiglu": null,
                "load": "/data/pipeline/phi35-moe-tp1pp8-mcore-base/",
                "evaluation-batch-size": 1,
                "micro-batch-size": 1,
                "max-new-tokens": 1,
                "padded-vocab-size": 32064,
                "make-vocab-size-divisible-by": 1,
                "position-embedding-type": "rope",
                "rope-scaling-type": "longrope",
                "longrope-freqs-type": "outer",
                "rope-scaling-original-max-position-embeddings": 4096,
                "long-mscale": 1.243163121016122,
                "short-mscale": 1.243163121016122,
                "long-factor": "1.0199999809265137,1.0299999713897705,1.0399999618530273,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.059999942779541,1.059999942779541,1.059999942779541,1.059999942779541,1.059999942779541,1.059999942779541,1.0999999046325684,1.1799999475479126,1.1799999475479126,1.3700000047683716,1.4899998903274536,2.109999895095825,2.8899998664855957,3.9499998092651367,4.299999713897705,6.429999828338623,8.09000015258789,10.690000534057617,12.050000190734863,18.229999542236328,18.84000015258789,19.899999618530273,21.420000076293945,26.200000762939453,34.28000259399414,34.590003967285156,38.730003356933594,40.22000503540039,42.54000473022461,44.000003814697266,47.590003967285156,54.750003814697266,56.19000244140625,57.44000244140625,57.4900016784668,61.20000076293945,61.540000915527344,61.75,61.779998779296875,62.06999969482422,63.11000061035156,63.43000030517578,63.560001373291016,63.71000289916992,63.92000198364258,63.94000244140625,63.94000244140625,63.96000289916992,63.980003356933594,64.0300064086914,64.0300064086914,64.0300064086914,64.04000854492188,64.10000610351562,64.19000244140625,64.20999908447266,64.75,64.95999908447266",
                "short-factor": "1.0,1.0399999618530273,1.0399999618530273,1.0399999618530273,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.059999942779541,1.059999942779541,1.0699999332427979,1.0699999332427979,1.0699999332427979,1.0699999332427979,1.1399999856948853,1.159999966621399,1.159999966621399,1.159999966621399,1.159999966621399,1.1799999475479126,1.1999999284744263,1.3199999332427979,1.3399999141693115,1.3499999046325684,1.3999998569488525,1.4799998998641968,1.4999998807907104,1.589999794960022,1.6499998569488525,1.71999990940094,1.8999998569488525,1.9099998474121094,1.9099998474121094,1.9899998903274536,1.9999998807907104,1.9999998807907104,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.0999999046325684,2.319999933242798,2.419999837875366,2.5899999141693115,2.7899999618530273",
                "tokenizer-not-use-fast": null,
                "normalization": "LayerNorm",
                "norm-epsilon": 1e-5,
                "rotary-base": 10000,
                "attention-dropout": 0.0,
                "hidden-dropout": 0.0,
                "add-qkv-bias": null,
                "disable-bias-linear": null,
                "add-dense-bias": null,
                "add-output-layer-bias": null,
                "use-flash-attn": null,
                "untie-embeddings-and-output-weights": null,
                "no-load-optim": null,
                "no-load-rng": null,
                "seed": 42,
                "bf16": null,
                "use-deter-comp": null
            }
        }
    ],

    "test_phi35_moe_greedy_search": [
        {
            "param": {
                "task": "greedy",
                "use-mcore-models": null,
                "moe-grouped-gemm": null,
                "spec": ["mindspeed_llm.tasks.models.spec.phi35_moe_spec", "layer_spec"],
                "tensor-model-parallel-size": 1,
                "pipeline-model-parallel-size": 8,
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path": "/data/hf/Phi-3.5-MoE-instruct-hf",
                "seq-length": 4096,
                "max-position-embeddings": 131072,
                "num-layers": 32,
                "hidden-size": 4096,
                "ffn-hidden-size": 6400,
                "num-attention-heads": 32,
                "group-query-attention": null,
                "num-query-groups": 8,
                "num-experts": 16,
                "moe-router-topk": 2,
                "moe-router-load-balancing-type": "sparsemixer_topk",
                "moe-input-jitter-eps": 0.01,
                "moe-permutation-async-comm": null,
                "swiglu": null,
                "load": "/data/pipeline/phi35-moe-tp1pp8-mcore-base",
                "micro-batch-size": 1,
                "max-new-tokens": 256,
                "padded-vocab-size": 32064,
                "make-vocab-size-divisible-by": 1,
                "position-embedding-type": "rope",
                "rope-scaling-type": "longrope",
                "longrope-freqs-type": "outer",
                "rope-scaling-original-max-position-embeddings": 4096,
                "long-mscale": 1.243163121016122,
                "short-mscale": 1.243163121016122,
                "long-factor": "1.0199999809265137,1.0299999713897705,1.0399999618530273,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.059999942779541,1.059999942779541,1.059999942779541,1.059999942779541,1.059999942779541,1.059999942779541,1.0999999046325684,1.1799999475479126,1.1799999475479126,1.3700000047683716,1.4899998903274536,2.109999895095825,2.8899998664855957,3.9499998092651367,4.299999713897705,6.429999828338623,8.09000015258789,10.690000534057617,12.050000190734863,18.229999542236328,18.84000015258789,19.899999618530273,21.420000076293945,26.200000762939453,34.28000259399414,34.590003967285156,38.730003356933594,40.22000503540039,42.54000473022461,44.000003814697266,47.590003967285156,54.750003814697266,56.19000244140625,57.44000244140625,57.4900016784668,61.20000076293945,61.540000915527344,61.75,61.779998779296875,62.06999969482422,63.11000061035156,63.43000030517578,63.560001373291016,63.71000289916992,63.92000198364258,63.94000244140625,63.94000244140625,63.96000289916992,63.980003356933594,64.0300064086914,64.0300064086914,64.0300064086914,64.04000854492188,64.10000610351562,64.19000244140625,64.20999908447266,64.75,64.95999908447266",
                "short-factor": "1.0,1.0399999618530273,1.0399999618530273,1.0399999618530273,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.0499999523162842,1.059999942779541,1.059999942779541,1.0699999332427979,1.0699999332427979,1.0699999332427979,1.0699999332427979,1.1399999856948853,1.159999966621399,1.159999966621399,1.159999966621399,1.159999966621399,1.1799999475479126,1.1999999284744263,1.3199999332427979,1.3399999141693115,1.3499999046325684,1.3999998569488525,1.4799998998641968,1.4999998807907104,1.589999794960022,1.6499998569488525,1.71999990940094,1.8999998569488525,1.9099998474121094,1.9099998474121094,1.9899998903274536,1.9999998807907104,1.9999998807907104,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.009999990463257,2.0999999046325684,2.319999933242798,2.419999837875366,2.5899999141693115,2.7899999618530273",
                "tokenizer-not-use-fast": null,
                "normalization": "LayerNorm",
                "norm-epsilon": 1e-5,
                "rotary-base": 10000,
                "attention-dropout": 0.0,
                "hidden-dropout": 0.0,
                "add-qkv-bias": null,
                "disable-bias-linear": null,
                "add-dense-bias": null,
                "add-output-layer-bias": null,
                "use-flash-attn": null,
                "untie-embeddings-and-output-weights": null,
                "no-load-optim": null,
                "no-load-rng": null,
                "seed": 42,
                "bf16": null,
                "use-deter-comp": null
            }
        }
    ],

    "test_preprocess_pretrain_data": [
        {
            "param": {
                "input": "/data/train-00000-of-00001-a09b74b3ef9c3b56.parquet",
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path": "/data/hf/Phi-3.5-MoE-instruct-hf"
            },
            "prefix": "alpaca"
        }
    ],

    "test_phi35_moe_hf2mg_tp1pp8": [
        {
            "param": {
                "use-mcore-models": null,
                "model-type-hf": "phi3.5-moe",
                "model-type": "GPT",
                "load-model-type": "hf",
                "save-model-type": "mg",
                "target-tensor-parallel-size": "1",
                "target-pipeline-parallel-size": "8",
                "load-dir": "/data/pipeline/phi35-moe-tp1pp8l8-mcore-base",
                "save-dir": "/data/cache",
                "tokenizer-model": "/data/hf/Phi-3.5-MoE-instruct-hf/tokenizer.model",
                "spec": "mindspeed_llm.tasks.models.spec.phi35_moe_spec layer_spec",
                "params-dtype": "bf16",
                "add-qkv-bias": null,
                "add-dense-bias": null,
                "moe-grouped-gemm": null
            }
        },
        {
            "Base_MD5" : [
                "5e77425553d3cbef",
                "e17a49f5ece96fed",
                "2f5d959d534bc2c7",
                "955cff3ccb965f77",
                "43c6232ebcb01703",
                "41fea6719f051079",
                "a2b62fa160d8babf",
                "c78fc899457ce0a1"
            ]
        }
    ]
}